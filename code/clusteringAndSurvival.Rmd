---
title: "additionalExamples"
author: "Grant Carr"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Purpose

Go through code examples of PCA, clustering, and survival modeling.

## Data

```{r}
#' example code for installing packages for first time:
#' install.packages("tidyverse")

library(tidyverse)
library(ggplot2)
library(survival)
library(ggfortify)
library(devtools)
#' install_github("jokergoo/ComplexHeatmap")
library(ComplexHeatmap)
library(umap)
```

```{r}
clinData <- read.csv(
  "/Users/lucymalmud/Desktop/BDSI/cancer-ds/tcia-git/data/clinicalData_clean.csv"
)
clinData <- clinData[,-1] # remove first column of row numbers since we have
# patient ID
```

```{r}
imFeatures <- read.csv(
  "/Users/lucymalmud/Desktop/BDSI/cancer-ds/tcia-git/data/imagingFeatures.csv"
)
imFeatures <- imFeatures[,-1]
```

## Data Editing

```{r}
clinData <- clinData %>% 
  mutate(
    Subtype = factor(
      case_when(
        Mol.Subtype == 0 ~ "Luminal",
        Mol.Subtype == 1 ~ "ER/PR+ and HER2+",
        Mol.Subtype == 2 ~ "HER2+",
        .default = "Triple Negative"
      ), levels = c("Luminal", "ER/PR+ and HER2+", "HER2+", "Triple Negative")
    )
  )
clinData <- clinData %>% mutate(
  surgeryDays = as.numeric(Days.to.Surgery..from.the.date.of.diagnosis.)
)
clinData$dead <- ifelse(
  clinData$Days.to.death..from.the.date.of.diagnosis. == "NP",
  0, 1
) # if days to death is not pertinent, then they did not die
clinData$survDays <- ifelse(
  clinData$dead == 1, as.numeric(clinData$Days.to.death..from.the.date.of.diagnosis.),
  pmax(
    as.numeric(clinData$Days.to.last.distant.recurrence.free.assemssment.from.the.date.of.diagnosis.),
    as.numeric(clinData$Days.to.last.local.recurrence.free.assessment..from.the.date.of.diagnosis.),
    as.numeric(clinData$Age.at.last.contact.in.EMR.f.u.days..from.the.date.of.diagnosis...last.time.patient.known.to.be.alive..unless.age.of.death.is.reported.in.such.case.the.age.of.death), na.rm = T
  )
)

clinData$recurrence <- as.numeric(clinData$Recurrence.event.s.)
#' make recurrence a numeric indicator
table(clinData["recurrence"], useNA = "if") # 87 recurrence, 2 missing
clinData$recurDays <- ifelse(
  clinData$recurrence == 0, as.numeric(clinData$survDays),
  ifelse(
    clinData$recurrence == 1,
    pmin(
    as.numeric(clinData$Days.to.distant.recurrence.from.the.date.of.diagnosis.),
    as.numeric(clinData$Days.to.local.recurrence..from.the.date.of.diagnosis.),
    na.rm = T
  ),
    NA
  )
  
)
```

## Principal Component Analysis

Principal component analysis (PCA) can be used to identify which variables in a dataset explain the most variability. Which features explain the most variability between patients in the MRI data? This can be a useful exploratory step when dealing with a large number of variables.

If you have 100 variables and 100 observations, PCA gives you 100 variables and 100 observations back, but the variables are all orthogonal (independent). The first variable, principal component 1 (PC1), has the most variance and explains the most variability and PC100 explains the least variability. The values of PC1 are a linear combination of the 100 original variables.

Always center and scale variables (mean 0 variance 1). We don't want the scale of variables to impact how we measure the most important variables.

```{r}
set.seed(1)
x <- abs(rnorm(100, 1, 0.1))
y <- abs(rnorm(100, 10, 2))
plot(x,y, xlim = c(0,15), ylim = c(0,15))
princomp(scale(cbind(x,y)), scores = T) %>% summary()
princomp(scale(cbind(x,y)), scores = T) %>% loadings()
```

Each component explains \~50% of variance in the data.

```{r}
set.seed(1)
x <- abs(rnorm(100, 1, 0.1))
y <- abs(rnorm(100, x*20, 2))
plot(x,y, ylim = c(14, 26), xlim = c(0,8))
princomp(scale(cbind(x,y)), scores = T) %>% summary()
princomp(scale(cbind(x,y)), scores = T) %>% loadings()
```

The first component explains 84% of the variance in the data. PC1 = 0.707x + 0.707y, indicating that PC1 reflects the positive relationship between x and y.

```{r}
imFeatures_complete <- imFeatures[complete.cases(imFeatures),-1]
featurePCA <- princomp(scale(imFeatures_complete), scores = T)
featurePC_scores <- as.data.frame(featurePCA$scores)

ggplot(
  featurePC_scores %>% mutate(
    Subtype = as.factor(clinData$Mol.Subtype[complete.cases(imFeatures)])
  ), 
  aes(Comp.1, Comp.2, col = Subtype)
) +
  geom_point()
ggplot(
  featurePC_scores %>% mutate(
    HER2 = as.factor(clinData$HER2[complete.cases(imFeatures)])
  ), 
  aes(Comp.1, Comp.2, col = HER2)
) +
  geom_point()


```

As is sometimes the case in complex data, it is difficult to see any pattern between PCA and the clinical outcomes I am interested in.

## Clustering

Clustering can be done on the original data or PCA. The goal of clustering is to group observations together that share similar features. Hierarchical clustering is where you start with every observation in their own cluster and merge the most similar clusters together until you have a single cluster. This results in a dendrogram.

Heat maps are a way of visualizing several variables at once. The rows represent observations, or in our case patient MRIs. Columns represent variables. Rows are clustered together to show which MRIs are similar by their features. Columns are also clustered together separately.

```{r}
Heatmap(
  scale(imFeatures_complete[,1:10]),
  column_labels = rep("", 10)
)

Heatmap(
  featurePC_scores[,1:10]
)
```

Another visualization tool is UMAP. UMAP is similar to PCA in that it is a dimension-reduction method, but it only returns two dimensions. It considers which observations are closely related and which are different and tries to arrange the points so that similar observations are near each other in the two-dimensional result.

```{r}
totalUMAP <- umap(imFeatures_complete)
ggplot(
  data.frame(
    totalUMAP$layout, 
    Subtype = clinData$Subtype[complete.cases(imFeatures)]
  ), 
  aes(X1, X2, col = Subtype)
) +
  geom_point()

ggplot(
  data.frame(
    totalUMAP$layout, 
    SurgeryDays = clinData$surgeryDays[complete.cases(imFeatures)]
  ) %>% filter(
    SurgeryDays < quantile(SurgeryDays, 0.99, na.rm = T),
    SurgeryDays > 0
  ), 
  aes(X1, X2, col = SurgeryDays)
) +
  geom_point() +
  scale_color_viridis_c()
  
```

Maybe there is some signal in the bottom left corner of the plot. Low values of both X1 and X2 tend to have shorter time from diagnosis to surgery.

## Survival Analysis

Typically we treat our data as being measured perfectly, such as age. We know exactly how old someone is. In survival analysis, we want to model the probability that a patient is alive at some arbitrary time $t$. For patients that died, we know exactly how long their survival time was. For patients that were still alive when they were last seen at the hospital, we want to incorporate the fact that we know they were still alive. Survival analysis is a special type of statistical modeling that can handle this complex data type. This will be covered in more detail in the future.

-   For some points, you have a definite value

-   For some people, you have minimum value (i.e. you don't know *when* they have died because they are still alive, but you can know at least how long that is)

A Kaplan-Meier curve is a way to plot the probability that a patient is alive at time $t$ over a range of times.

```{r}
kmFit <- survfit(Surv(survDays, dead) ~ 1, data = clinData)
autoplot(kmFit)

kmFit_subtype <- survfit(Surv(survDays, dead) ~ Subtype, data = clinData)
autoplot(kmFit_subtype) +
  labs(col = "Subtype", fill = "Subtype")
```

Here we can see the general trend in the data that most patients had great survival. The probability that a patient is alive after 3000 days, or 8 years, is over 90%. Looking at the K-M plot for each subtype, triple-negative breast cancer patients had the worst survival in our data while ER/PR+ and HER2+ patients had the best.

```{r}
library(gtsummary)
tbl_summary(clinData[,-1])
```

```{r}
# If you needed to change a datatype
x = c("1", "2")
x = as.numeric(x)
x
```
